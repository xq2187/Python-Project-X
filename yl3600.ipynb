{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-df05a4659f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-6-510f9bfd1aa6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-510f9bfd1aa6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    path1=('C:\\Users\\csu\\Desktop\\zillow\\properties_2017.csv')\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "path1=('C:\\Users\\csu\\Desktop\\zillow\\properties_2017.csv')\n",
    "path2=('C:\\Users\\csu\\Desktop\\zillow\\train_2017.csv')\n",
    "train_data=pd.read_csv(path1)\n",
    "test_data=pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4dda1b59424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the variables into numerical variables and categorical variables\n",
    "num_vari=[]\n",
    "cate_vari=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['SalePrice'].describe() ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate missing data\n",
    "total_missing = train_data.isnull().sum().sort_values(ascending=False)\n",
    "missing_ratio = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total_missing, missing_ratio], axis=1, keys=['total_missing', 'missing_ratio'])\n",
    "missing_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ratio of missing\n",
    "f, ax = plt.subplots(figsize=(18, 10))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=missing_data.index, y=missing_data.missing_ratio)\n",
    "plt.xlabel('properties', fontsize=18)\n",
    "plt.ylabel('Ratio of missing values', fontsize=18)\n",
    "plt.title('Ratio of missing data by properties', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation matrix\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "def correlation_map(df):\n",
    "    correlation = train_data.corr()\n",
    "    plt.subplots(figsize=(15,10))\n",
    "    plt.title('Correlation Map', fontsize=20)\n",
    "    sns.heatmap(correlation, xticklabels=correlation.columns, yticklabels=correlation.columns)\n",
    "    \n",
    "correlation_map(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do analysis on variables with high correlation\n",
    "corr_df_sel= corr_df.ix[(corr_df['corr_values']>0.02)| (corr_df['corr_values'] < -0.01)]]\n",
    "corr_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw heatmap of these high correlative variables\n",
    "cols_to_use = corr_df_sel.col_labels.tolist()\n",
    "\n",
    "temp_df = train_df[cols_to_use]\n",
    "corrmat = temp_df.corr(method='spearman')\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "sns.heatmap(corrmat, vmax=1., square=True)\n",
    "plt.title(\"Important variables correlation map\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the correlation between these important variables and SalePrice\n",
    "# variable 1\n",
    "col = \"variable 1\"\n",
    "ulimit = np.percentile(train_df[col].values, 99.5)\n",
    "llimit = np.percentile(train_df[col].values, 0.5)\n",
    "train_df[col].ix[train_df[col]>ulimit] = ulimit\n",
    "train_df[col].ix[train_df[col]<llimit] = llimit\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=train_df.variable 1.values, y=train_df.SalePrice.values, size=10, color=color[4])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('variable 1', fontsize=12)\n",
    "plt.title(\"variable 1 Vs SalePrice\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#variable 2\n",
    "ol = \"variable 2\"\n",
    "ulimit = np.percentile(train_df[col].values, 99.5)\n",
    "llimit = np.percentile(train_df[col].values, 0.5)\n",
    "train_df[col].ix[train_df[col]>ulimit] = ulimit\n",
    "train_df[col].ix[train_df[col]<llimit] = llimit\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=train_df.variable 2.values, y=train_df.SalePrice.values, size=10, color=color[4])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('variable 2', fontsize=12)\n",
    "plt.title(\"variable 2 Vs SalePrice\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#variable 3 \n",
    "ol = \"variable 1\"\n",
    "ulimit = np.percentile(train_df[col].values, 99.5)\n",
    "llimit = np.percentile(train_df[col].values, 0.5)\n",
    "train_df[col].ix[train_df[col]>ulimit] = ulimit\n",
    "train_df[col].ix[train_df[col]<llimit] = llimit\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=train_df.variable 1.values, y=train_df.SalePrice.values, size=10, color=color[4])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('variable 1', fontsize=12)\n",
    "plt.title(\"variable 1 Vs SalePrice\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# variable 4\n",
    "ol = \"variable 1\"\n",
    "ulimit = np.percentile(train_df[col].values, 99.5)\n",
    "llimit = np.percentile(train_df[col].values, 0.5)\n",
    "train_df[col].ix[train_df[col]>ulimit] = ulimit\n",
    "train_df[col].ix[train_df[col]<llimit] = llimit\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=train_df.variable 1.values, y=train_df.SalePrice.values, size=10, color=color[4])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('variable 1', fontsize=12)\n",
    "plt.title(\"variable 1 Vs SalePrice\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# variable 5\n",
    "ol = \"variable 1\"\n",
    "ulimit = np.percentile(train_df[col].values, 99.5)\n",
    "llimit = np.percentile(train_df[col].values, 0.5)\n",
    "train_df[col].ix[train_df[col]>ulimit] = ulimit\n",
    "train_df[col].ix[train_df[col]<llimit] = llimit\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=train_df.variable 1.values, y=train_df.SalePrice.values, size=10, color=color[4])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('variable 1', fontsize=12)\n",
    "plt.title(\"variable 1 Vs SalePrice\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value by the median for numerical \n",
    "def fillmedian(num_vari):\n",
    "    for i in num_vari:\n",
    "        train_data[i] = train_data[col].transform(lambda x: x.fillna(x.median()))\n",
    "fillmedian(num_vari)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value by the mode for category numerical\n",
    "def fillmode(cate_vari):\n",
    "    for i in cato_vari:\n",
    "        train_data[i] = train_data[i].fillna(train_data[i].mode()[0])\n",
    "fillmode(cate_vari)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is any missing_value left\n",
    "def left_missing(dataset):\n",
    "    val = dataset.isnull().sum().max()\n",
    "    if val>0:\n",
    "        raise ValueError('There is still missing_value left!')\n",
    "data=train_data['airconditioningtypeid']\n",
    "left_missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics analysis\n",
    "# SalePrice\n",
    "#normal distribution plot\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "sns.distplot(train_data['SalePrice'] , color='b', fit=norm);\n",
    "(mu, sigma) = norm.fit(train_daata['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#log transformation\n",
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train_data[\"SalePrice\"] = np.log1p(train_data[\"SalePrice\"])\n",
    "sns.distplot(train_data['SalePrice'] , fit=norm);\n",
    "(mu, sigma) = norm.fit(train_data['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train_data['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
